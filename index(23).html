<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Catherine Gaudet</title>

    <meta name="author" content="Catherine Gaudet">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Catherine Gaudet
                </p>
                <p>I'm an aspiring content creator and a student at <a href="yorku.com">York University</a> in Toronto, where I am pursuing a Bachelor of Commerce.
                </p>
                <p>
                  I have completed a Business Marketing diploma at Humber College where I have acquired a wide range of applied creative skills, and experience in <a href="https://hootsuite.com">HootSuite</a>, and <a href="https://adobe.com">Adobe Express</a>, and <a href="https://audacity.com">Audacity</a>
                </p>
                <p style="text-align:center">
                  <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">Resume</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jonbarron/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Portfolio</h2>
                <p>
                  I have curated a portfolio that demonstrates my ability to create memorable content</span>.
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="dualdefocus_stop()" onmouseover="dualdefocus_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualdefocus_image'>
                    <img src='images/dualdefocus_after.jpg' width="160"></div>
                  <img src='images/dualdefocus_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dualdefocus_start() {
                    document.getElementById('dualdefocus_image').style.opacity = "1";
                  }

                  function dualdefocus_stop() {
                    document.getElementById('dualdefocus_image').style.opacity = "0";
                  }
                  dualdefocus_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://imaging.cs.cmu.edu/dual_pixels/">
                  <span class="papertitle">Defocus Map Estimation and Deblurring from a Single Dual-Pixel Image</span>
                </a>
                <br>
                <a href="https://shumianxin.github.io/">Shumian Xin</a>,
                <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
                <a href="https://tianfan.info/">Tianfan Xue</a>,
                <strong>Jonathan T. Barron</strong>, <br>
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
                <a href="https://www.cs.cmu.edu/~igkioule/">Ioannis Gkioulekas</a>,
                <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://imaging.cs.cmu.edu/dual_pixels/">project page</a> /
                <a href="https://github.com/cmu-ci-lab/dual_pixel_defocus_estimation_deblurring">code</a>
                <br>
                <p></p>
                <p>
                  Multiplane images can be used to simultaneously deblur dual-pixel images, despite variable defocus due to depth variation in the scene.
                </p>
              </td>
            </tr> 
            <tr onmouseout="skyopt_stop()" onmouseover="skyopt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='skyopt_image'>
                    <img src='images/skyopt_after.jpg' width="160"></div>
                  <img src='images/skyopt_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function skyopt_start() {
                    document.getElementById('skyopt_image').style.opacity = "1";
                  }

                  function skyopt_stop() {
                    document.getElementById('skyopt_image').style.opacity = "0";
                  }
                  skyopt_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2006.10172">
                  <span class="papertitle">Sky Optimization: Semantically Aware Image Processing of Skies in Low-Light Photography</span>
                </a>
                <br>
                <a href="https://sites.google.com/corp/view/orly-liba/">Orly Liba</a>,
                <a href="https://www.linkedin.com/in/longqicai/en-us">Longqi Cai</a>,
                <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
                <a href="https://research.google/people/EladEban/">Elad Eban</a>,
                <a href="https://research.google/people/YairMovshovitzAttias/">Yair Movshovitz-Attias</a>, <br>
                <a href="https://scholar.google.com/citations?user=2jXxOYQAAAAJ">Yael Pritch</a>,
                <a href="https://www.linkedin.com/in/huizhong-chen-00776432">Huizhong Chen</a>,
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>NTIRE CVPRW</em>, 2020  
                <br>
                <a href="https://google.github.io/sky-optimization/">project page</a>
                <p></p>
                <p>If you want to photograph the sky, it helps to know where the sky is.</p>
              </td>
            </tr>  

            <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='nightsight_image'><img src='images/nightsight_after.jpg'></div>
                  <img src='images/nightsight_before.jpg'>
                </div>
                <script type="text/javascript">
                  function nightsight_start() {
                    document.getElementById('nightsight_image').style.opacity = "1";
                  }

                  function nightsight_stop() {
                    document.getElementById('nightsight_image').style.opacity = "0";
                  }
                  nightsight_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1910.11336">
                  <span class="papertitle">Handheld Mobile Photography in Very Low Light</span>
                </a>
                <br>
                <a href="https://sites.google.com/site/orlylibaprofessional/">Orly Liba</a>,
                <a href="https://scholar.google.com/citations?user=6PhlPWMAAAAJ">Kiran Murthy</a>,
                <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
                <a href="https://www.timothybrooks.com/">Timothy Brooks</a>,
                <a href="https://tianfan.info/">Tianfan Xue</a>,
                <a href="https://scholar.google.com/citations?user=qgc_jY0AAAAJ">Nikhil Karnad</a>,
                <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://ai.google/research/people/105641/">Dillon Sharlet</a>,
                <a href="http://www.geisswerks.com/">Ryan Geiss</a>,
                <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>,
                <a href="https://scholar.google.com/citations?user=2jXxOYQAAAAJ">Yael Pritch</a>,
                <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a>
                <br>
                <em>SIGGRAPH Asia</em>, 2019
                <br>
                <a href="https://github.com/google/night-sight/tree/master/docs">project page</a>
                <br>
                <p></p>
                <p>By rethinking metering, white balance, and tone mapping, we can take pictures in places too dark for humans to see clearly.</p>
              </td>
            </tr>

            <tr onmouseout="font_stop()" onmouseover="font_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='font_image'><img src='images/font_after.png'></div>
                  <img src='images/font_before.png'>
                </div>
                <script type="text/javascript">
                  function font_start() {
                    document.getElementById('font_image').style.opacity = "1";
                  }

                  function font_stop() {
                    document.getElementById('font_image').style.opacity = "0";
                  }
                  font_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1910.00748">
                  <span class="papertitle">A Deep Factorization of Style and Structure in Fonts</span>
                </a>
                <br>
                <a href="http://www.cs.cmu.edu/~asrivats/">Nikita Srivatsan</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>,
                <a href="http://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>
                <br>
                <em>EMNLP</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <p></p>
                <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
              </td>
            </tr>
            
            <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dpzlearn_image'><img src='images/dpzlearn_after.jpg'></div>
                  <img src='images/dpzlearn_before.jpg'>
                </div>
                <script type="text/javascript">
                  function dpzlearn_start() {
                    document.getElementById('dpzlearn_image').style.opacity = "1";
                  }

                  function dpzlearn_stop() {
                    document.getElementById('dpzlearn_image').style.opacity = "0";
                  }
                  dpzlearn_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1904.05822">
                  <span class="papertitle">Learning Single Camera Depth Estimation using Dual-Pixels</span>
                </a>
                <br>
                <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
                <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
                <a href="">Sameer Ansari</a>,
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>ICCV</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://github.com/google-research/google-research/tree/master/dual_pixels">code</a> /
                <a href="data/GargICCV2019.bib">bibtex</a>
                <p></p>
                <p>Considering the optics of dual-pixel image sensors improves monocular depth estimation techniques.</p>
              </td>
            </tr>
            <tr onmouseout="bs_stop()" onmouseover="bs_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='bs_image'><img src='images/BS_after.jpg'></div>
                  <img src='images/BS_before.jpg'>
                </div>
                <script type="text/javascript">
                  function bs_start() {
                    document.getElementById('bs_image').style.opacity = "1";
                  }

                  function bs_stop() {
                    document.getElementById('bs_image').style.opacity = "0";
                  }
                  bs_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1zFzCaFwkGK1EGmJ_KEqb-ZsRJhfUKN2S/view?usp=sharing">
                  <span class="papertitle">The Fast Bilateral Solver</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>,
                <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
                <br>
                <em>ECCV</em>, 2016 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
                <br>
                <a href="http://arxiv.org/abs/1511.03296">arXiv</a> /
                <a href="data/BarronPooleECCV2016.bib">bibtex</a> /
                <a href="http://videolectures.net/eccv2016_barron_bilateral_solver/">video (they messed up my slides, use &rarr;)</a> /
                <a href="https://drive.google.com/file/d/19x1AeN0PFus6Pjrd8nR-vCmJ6bNEefsC/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/1p9nduiymK9jUh7WfwlsMjBfW8RoNe_61/view?usp=sharing">PDF</a>) /
                <a href="https://github.com/poolio/bilateral_solver">code</a> /
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmaDI3bm5VeDRxams/view?usp=sharing&resourcekey=0-pmkbnOuy8caA7-3GGSfeNQ">depth super-res results</a> /
                <a href="data/BarronPooleECCV2016_reviews.txt">reviews</a>
                <p></p>
                <p>Our solver smooths things better than other filters and faster than other optimization algorithms, and you can backprop through it.</p>
              </td>
            </tr>

            <tr onmouseout="diverdi_stop()" onmouseover="diverdi_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='diverdi_image'><img src='images/diverdi_after.jpg'></div>
                  <img src='images/diverdi_before.jpg'>
                </div>
                <script type="text/javascript">
                  function diverdi_start() {
                    document.getElementById('diverdi_image').style.opacity = "1";
                  }

                  function diverdi_stop() {
                    document.getElementById('diverdi_image').style.opacity = "0";
                  }
                  diverdi_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1mmT-LuK_eBZsl3qp4-fAshEPdgfbgvNE/view?usp=sharing">
                  <span class="papertitle">Geometric Calibration for Mobile, Stereo, Autofocus Cameras</span>
                </a>
                <br>
                <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>WACV</em>, 2016
                <br>
                <a href="data/Diverdi2016.bib">bibtex</a>
                <p></p>
                <p>Standard techniques for stereo calibration don't work for cheap mobile cameras.</p>
              </td>
            </tr>

            <tr onmouseout="dt_stop()" onmouseover="dt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                  <img src='images/DT_image.jpg'>
                </div>
                <script type="text/javascript">
                  function dt_start() {
                    document.getElementById('dt_image').style.opacity = "1";
                  }

                  function dt_stop() {
                    document.getElementById('dt_image').style.opacity = "0";
                  }
                  dt_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                  <span class="papertitle">Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</span>
                </a>
                <br>
                <em>CVPR</em>, 2016
                <br>
                <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
                <br>
                <a href="data/Chen2016.bib">bibtex</a> /
                <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
                <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
                <p></p>
                <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
              </td>
            </tr>

            <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                  <img src='images/ccc_before.jpg'>
                </div>
                <script type="text/javascript">
                  function ccc_start() {
                    document.getElementById('ccc_image').style.opacity = "1";
                  }

                  function ccc_stop() {
                    document.getElementById('ccc_image').style.opacity = "0";
                  }
                  ccc_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                  <span class="papertitle">Convolutional Color Constancy</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>
                <br>
                <em>ICCV</em>, 2015
                <br>
                <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
                <p></p>
                <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/Shelhamer2015.jpg'>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                  <span class="papertitle">Scene Intrinsics and Depth from a Single Image</span>
                </a>
                <br>
                <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV Workshop</em>, 2015
                <br>
                <a href="data/Shelhamer2015.bib">bibtex</a>
                <p></p>
                <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0" onmouseout="defocus_stop()" onmouseover="defocus_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='lens_blurry' class='hidden'><img src="images/BarronCVPR2015_anim.gif"></div>
                <div id='lens_sharp'>
                  <a href="images/BarronCVPR2015_anim.gif"><img src="images/BarronCVPR2015_still.jpg"></a>
                </div>
                <script type="text/javascript">
                  function defocus_start() {
                    document.getElementById('lens_blurry').style.display = 'inline';
                    document.getElementById('lens_sharp').style.display = 'none';
                  }

                  function defocus_stop() {
                    document.getElementById('lens_blurry').style.display = 'none';
                    document.getElementById('lens_sharp').style.display = 'inline';
                  }
                  defocus_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1R4RdaBZIs-uJobhIFs9yKf3jIsaHQNH0/view?usp=sharing">
                  <span class="papertitle">Fast Bilateral-Space Stereo for Synthetic Defocus</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <a href="http://people.csail.mit.edu/yichangshih/">YiChang Shih</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>
                <br>
                <em>CVPR</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://drive.google.com/file/d/125qgMdqeT1vojMIijIKcOF099LjUgUOL/view?usp=sharing">abstract</a> /
                <a href="https://drive.google.com/file/d/1HGGvVOGxmPjvgdK5q3UD1Qb5Nttg6kq9/view?usp=sharing">supplement</a> /
                <a href="data/BarronCVPR2015.bib">bibtex</a> /
                <a href="http://techtalks.tv/talks/fast-bilateral-space-stereo-for-synthetic-defocus/61624/">talk</a> /
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSzZZdUJSMllSUkE/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmZ1ZXUzBCWDJYeFU">PDF</a>)
                <p></p>
                <p>By embedding a stereo optimization problem in "bilateral-space" we can very quickly solve for an edge-aware depth map, letting us render beautiful depth-of-field effects.</p>
                <p>This technology is used by the <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Google Camera "Lens Blur"</a> feature. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal">
                  <span class="papertitle">Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</span>
                </a>
                <br>
                <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>TPAMI</em>, 2017
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
                <p></p>
                <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
                <p>This paper subsumes our CVPR 2014 paper.</p>
              </td>
            </tr>

            <tr bgcolor="#ffffd0" onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='sirfs_image'>
                    <a href="images/Estee.png"><img src='images/Estee_160.png' style="border-style: none"></a>
                  </div>
                  <a href="images/Estee.png"><img src='images/Estee_160_prodB2.png' style="border-style: none"></a>
                </div>
                <script type="text/javascript">
                  function sirfs_start() {
                    document.getElementById('sirfs_image').style.opacity = "1";
                  }

                  function sirfs_stop() {
                    document.getElementById('sirfs_image').style.opacity = "0";
                  }
                  sirfs_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <a href="https://arxiv.org/abs/2010.03592" id="SIRFS">
                    <span class="papertitle">Shape, Illumination, and Reflectance from Shading</span>
                  </a>
                  <br>
                  <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                  <br>
                  <em>TPAMI</em>, 2015
                  <br>
                  <a href="data/BarronMalikTPAMI2015.bib">bibtex</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmVWpfa19mbUxIYW8/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmazJvLXJUb0NuM1U/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmTDBUWE96VHJndjg/view?usp=sharing">PDF</a>) / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a> / <a href="https://drive.google.com/file/d/1vg9Rb-kBntSTnTCzVgFlskkPXvTB_5aq/view?usp=sharing">code &amp; data</a> / <a href="https://drive.google.com/file/d/11X5Zfjy7Q7oP_V2rtqy2f5-x9YgQUAFd/view?usp=sharing">kudos</a>
                </p>
                <p>
                  We present <strong>SIRFS</strong>, which can estimate shape, chromatic illumination, reflectance, and shading from a single image of an masked object.
                </p>
                <p>
                  This paper subsumes our CVPR 2011, CVPR 2012, and ECCV 2012 papers.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                  <span class="papertitle">Multiscale Combinatorial Grouping</span>
                </a>
                <br>
                <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2014
                <br>
                <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
              </td>
            </tr>

            <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='flyspin' class='hidden'><img src="images/BarronICCV2013_160.gif"></div>
                <div id='flystill'>
                  <a href="images/BarronICCV2013.gif"><img src="images/BarronICCV2013_160.jpg"></a>
                </div>
                <script type="text/javascript">
                  function flyspin_start() {
                    document.getElementById('flyspin').style.display = 'inline';
                    document.getElementById('flystill').style.display = 'none';
                  }

                  function flyspin_stop() {
                    document.getElementById('flyspin').style.display = 'none';
                    document.getElementById('flystill').style.display = 'inline';
                  }
                  flyspin_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing">
                  <span class="papertitle">Volumetric Semantic Segmentation using Pyramid Context Features</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>,
                <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>ICCV</em>, 2013
                <br>
                <a href="https://drive.google.com/file/d/1htiLpMAcYLtuBthmAb4XHnOYxUbkfnqR/view?usp=sharing">supplement</a> /
                <a href="https://drive.google.com/file/d/1qoYeFNa443myn2SfcdhmCsYBqE9xQrPD/view?usp=sharing">poster</a> /
                <a href="data/BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
                <p>
                  We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmbG1tOGIta3N1Wjg/view?usp=sharing" id="3DSP">
                  <span class="papertitle">3D Self-Portraits</span>
                </a>
                <br>
                <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
                <br>
                <em>SIGGRAPH Asia</em>, 2013
                <br>
                <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="data/3DSP_siggraphAsia2013.bib">bibtex</a>
                <p>Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.</p>
              </td>
            </tr>

            <tr onmouseout="rgbd_stop()" onmouseover="rgbd_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='rgbd_anim' class='hidden'><img src="images/SceneSIRFS.gif"></div>
                <div id='rgbd_still'><img src="images/SceneSIRFS-still.jpg"></div>
                <script type="text/javascript">
                  function rgbd_start() {
                    document.getElementById('rgbd_anim').style.display = 'inline';
                    document.getElementById('rgbd_still').style.display = 'none';
                  }

                  function rgbd_stop() {
                    document.getElementById('rgbd_anim').style.display = 'none';
                    document.getElementById('rgbd_still').style.display = 'inline';
                  }
                  rgbd_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1snypSLhzC0jXCchJRsWpcDZ7Es5hDmXo/view?usp=sharing">
                  <span class="papertitle">Intrinsic Scene Properties from a Single RGB-D Image</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2013 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://drive.google.com/file/d/1cLUw72WpgdZ_3TQAjJABdgywqjBfn_Mq/view?usp=sharing">supplement</a> / <a href="data/BarronMalikCVPR2013.bib">bibtex</a> / <a href="http://techtalks.tv/talks/intrinsic-scene-properties-from-a-single-rgb-d-image/58614/">talk</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmWW1CZGJPbi12R0k/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/19q3EFf6GIb4UFcCN2DVU2jVKpxRj5kxf/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmMzQ4ZVp1SWdnVkk/view?usp=sharing">PDF</a>) / <a href="https://drive.google.com/open?id=1ZbPScVA6Efqd-ESvojl92sw8K-82Xxry">code &amp; data</a>
                <p>By embedding mixtures of shapes &amp; lights into a soft segmentation of an image, and by leveraging the output of the Kinect, we can extend SIRFS to scenes.
                  <br>
                  <br>TPAMI Journal version: <a href="https://drive.google.com/file/d/1iQiUxZvjPPnb8rFCwXYesTgFSRk7mkAq/view?usp=sharing">version</a> / <a href="data/BarronMalikTPAMI2015B.bib">bibtex</a>
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Boundary.jpg" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1H4YPovfrvcce3HGMEhidwU2l2fTcNR5y/view?usp=sharing">
                  <span class="papertitle">Boundary Cues for 3D Object Shape Recovery</span>
                </a>
                <br>
                <a href="http://www.kevinkarsch.com/">Kevin Karsch</a>,
                <a href="http://web.engr.illinois.edu/~liao17/">Zicheng Liao</a>,
                <a href="http://web.engr.illinois.edu/~jjrock2/">Jason Rock</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.illinois.edu/homes/dhoiem/">Derek Hoiem</a>
                <br>
                <em>CVPR</em>, 2013
                <br>
                <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmLUQ5SVJTcUZIYXc/view?usp=sharing">supplement</a> / <a href="data/KarschCVPR2013.bib">bibtex</a>
                <p>Boundary cues (like occlusions and folds) can be used for shape reconstruction, which improves object recognition for humans and computers.</p>
              </td>
            </tr>

            <tr onmouseout="eccv12_stop()" onmouseover="eccv12_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div id='eccv12_anim' class='hidden'>
                  <a href="https://drive.google.com/file/d/1brxb58CfRPe7KEER4Q_fYS9B_J-hiS0t/view?usp=sharing"><img src="images/ECCV2012_small.gif"></a>
                </div>
                <div id='eccv12_still'><img src="images/ECCV2012_still.jpg"></div>
                <script type="text/javascript">
                  function eccv12_start() {
                    document.getElementById('eccv12_anim').style.display = 'inline';
                    document.getElementById('eccv12_still').style.display = 'none';
                  }

                  function eccv12_stop() {
                    document.getElementById('eccv12_anim').style.display = 'none';
                    document.getElementById('eccv12_still').style.display = 'inline';
                  }
                  eccv12_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1NczR4pJ-s0YBjCe0rCevMt8IM5JPuUrc/view?usp=sharing">
                  <span class="papertitle">Color Constancy, Intrinsic Images, and Shape Estimation</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>ECCV</em>, 2012
                <br>
                <a href="https://drive.google.com/file/d/1zuxhWZ3i6THvuRRBeE7dM_BJfDxO72Fq/view?usp=sharing">supplement</a> /
                <a href="data/BarronMalikECCV2012.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/12x8mhqpFsA6p0u6ZQW-ieRKF8hlQBKKe/view?usp=sharing">poster</a> /
                <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr onmouseout="cvpr12_stop()" onmouseover="cvpr12_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" style="height: 120px">
                  <div class="two" id='cvpr12_image' style="height: 120px">
                    <img src='images/BarronCVPR2012_after.jpg' style="border-style: none">
                  </div>
                  <img src='images/BarronCVPR2012_before.jpg' style="border-style: none">
                </div>
                <script type="text/javascript">
                  function cvpr12_start() {
                    document.getElementById('cvpr12_image').style.opacity = "1";
                  }

                  function cvpr12_stop() {
                    document.getElementById('cvpr12_image').style.opacity = "0";
                  }
                  cvpr12_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/17RfINbE2dr2EjXp9MtGO0MHJLQmQVhvT/view?usp=sharing">
                  <span class="papertitle">Shape, Albedo, and Illumination from a Single Image of an Unknown Object</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2012
                <br>
                <a href="https://drive.google.com/file/d/1Im_bUI42AP9VPoNtsjLajvtLRiwv39k3/view?usp=sharing">supplement</a> /
                <a href="data/BarronMalikCVPR2012.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1IAlSF4k3_CEL9dfbaMiNTFPBoEkLhsRl/view?usp=sharing">poster</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                  <span class="papertitle">A Category-Level 3-D Object Dataset: Putting the Kinect to Work</span>
                </a>
                <br>
                <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
                <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
                <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
                <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
                <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
                <br>
                <em>ICCV 3DRR Workshop</em>, 2011
                <br>
                <a href="data/B3DO_ICCV_2011.bib">bibtex</a> /
                <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
                <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/safs.jpg" alt="safs_small" width="160" height="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                  <span class="papertitle">High-Frequency Shape and Albedo from Shading using Natural Image Statistics</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>CVPR</em>, 2011
                <br>
                <a href="data/BarronMalikCVPR2011.bib">bibtex</a>
                <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fast_texture.jpg" alt="fast-texture" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing">
                  <span class="papertitle">Discovering Efficiency in Coarse-To-Fine Texture Classification</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>Technical Report</em>, 2010
                <br>
                <a href="data/BarronTR2010.bib">bibtex</a>
                <p>A model and feature representation that allows for sub-linear coarse-to-fine semantic segmentation.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/prl.jpg" alt="prl" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <span class="papertitle">Parallelizing Reinforcement Learning</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                <br>
                <em>Technical Report</em>, 2009
                <br>
                <a href="data/BarronPRL2009.bib">bibtex</a>
                <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 136, 2008
                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
